{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Machine Learning Project"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Introduction"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The aim of this project is to predict the presence of heart disease using a dataset obtained from the UCL Machine Learning repository. The dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/statlog+%28heart%29). \n\n*INSERT OUTLINE OF METHODOLOGY AFTER PROJECT*"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Description"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Our data consists of 270 instances with 13 descriptive features, and a target feature having two classes which indicate the presence or absence of heart disease. Hence, this is a binary classification problem. As is, our dataset contains no missing values.\n\nThe following explanation of the descriptive features is extracted from the dataset description on the [UCL website](https://archive.ics.uci.edu/ml/datasets/statlog+%28heart%29):\n* age - **numerical**\n* sex - **binary**\n* chest pain type - **nominal**\n* resting blood pressure - **numerical**\n* serum cholestoral in mg/dl - **numerical**      \n* fasting blood sugar > 120 mg/dl - **binary**\n* resting electrocardiographic results - **nominal**\n* maximum heart rate achieved - **numerical**\n* exercise induced angina - **binary**\n* oldpeak = ST depression induced by exercise relative to rest - **numerical**\n* the slope of the peak exercise ST segment - **ordinal**\n* number of major vessels (0-3) colored by flourosopy - **numerical**    \n* thal - **nominal**\n\nEach of the nominal features has been integer encoded, which is a miselading representation of the data and will be addressed in the processing stage. \n\nTime to import our dataset as well as any modules we will be using, and do some preliminary configuration."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\n# Ignore python warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# display all columns\npd.set_option('display.max_columns', None) \n\n# read in and configure data with column names\n# col_names = ['age', 'sex', 'chest_pain_type', 'resting_bp', 'serum_cholestoral', 'fasting_blood_sugar', 'resting_ecg_results', 'max_hr_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_of_peak_exercise', 'no_of_major_vessels', 'thal', 'target']\n# these names are abbreviated below for space\ncol_names = ['age', 'sex', 'cpt', 'rb', 'sc', 'fbs', 'rer', 'mha', 'eia', 'old', 'sope', 'nomv', 'thal', 'target'] \ndata = pd.read_csv('heart.csv',names=col_names,header=None)\n\n# separate target feature\ntarget = data['target']\ndata.drop(columns=['target'],inplace=True)",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that we have our dataset imported and our target feature separated we can have a brief look at our dataset using python."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"----------\")\nprint(f\"Shape of the dataset is {data.shape} \\n\")\nprint(\"----------\")\nprint(f\"Each of the descriptive features have the following types:\\n{data.dtypes}\\n\")\nprint(\"----------\")\nprint(f\"Each of the descriptive features have the following number of unique values:\\n{data.nunique()}\\n\")\nprint(\"----------\")\nprint(f\"The dataset contains no missing values:\\n{data.isna().sum()}\\n\")",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "----------\nShape of the dataset is (270, 13) \n\n----------\nEach of the descriptive features have the following types:\nage     float64\nsex     float64\ncpt     float64\nrb      float64\nsc      float64\nfbs     float64\nrer     float64\nmha     float64\neia     float64\nold     float64\nsope    float64\nnomv    float64\nthal    float64\ndtype: object\n\n----------\nEach of the descriptive features have the following number of unique values:\nage      41\nsex       2\ncpt       4\nrb       47\nsc      144\nfbs       2\nrer       3\nmha      90\neia       2\nold      39\nsope      3\nnomv      4\nthal      3\ndtype: int64\n\n----------\nThe dataset contains no missing values:\nage     0\nsex     0\ncpt     0\nrb      0\nsc      0\nfbs     0\nrer     0\nmha     0\neia     0\nold     0\nsope    0\nnomv    0\nthal    0\ndtype: int64\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Preparation\n<a id='dataprep'></a>\nWhile our dataset comes to us fairly clean, there is still much data preparation to do before we can get to the business of predictive modelling.\n\nFirst of all, we must integer encode the target feature. It currently holds the values (1) for the absence of heart disease, and (2) for the presence of heart disease. Since the presence is our postive feature, we wish to map this to (1) and the absence to (0)."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# firstly we integer encode target feature \nprint(\"Target before encoding: \",np.unique(target,return_counts=True))\nencoded_target = np.where(target==1,0,1)\nprint(\"Target after encoding: \",np.unique(encoded_target,return_counts=True))",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Target before encoding:  (array([1, 2]), array([150, 120]))\nTarget after encoding:  (array([0, 1]), array([150, 120]))\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We now turn to our nominal features (chest pain type, resting electrocardiographic results, and thal) which have been integer encoded. As integer encoding assumes an ordering, we consider it bad practice to integer encode nominal features, so we will undo this encoding to repace it with a one-hot encoding scheme."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# output the value counts for variable 'cpt'\nprint(f\"Before processing the variable \\\"cpt\\\" has the following value counts:\\n{data['cpt'].value_counts()}\\n\")\n\n# we then map each of them to the following categorical levels\ncpt_mappings = {1.0 : 'cpt1', 2.0 : 'cpt2', 3.0 : 'cpt3', 4.0 : 'cpt4'}\ndata['cpt'].replace(cpt_mappings,inplace=True)\n\n# output the result\nprint(f\"After processing the variable \\\"cpt\\\" has the following value counts:\\n{data['cpt'].value_counts()}\\n\")\n\n# output the value counts for variable 'rer'\nprint(f\"Before processing the variable \\\"rer\\\" has the following value counts:\\n{data['rer'].value_counts()}\\n\")\n\n# we then map each of them to the following categorical levels\nrer_mappings = {0.0 : 'rer0', 1.0 : 'rer1', 2.0 : 'rer2'}\ndata['rer'].replace(rer_mappings,inplace=True)\n\n# output the result\nprint(f\"After processing the variable \\\"rer\\\" has the following value counts:\\n{data['rer'].value_counts()}\\n\")\n\n# output the value counts for variable 'thal'\nprint(f\"Before processing the variable \\\"thal\\\" has the following value counts:\\n{data['thal'].value_counts()}\\n\")\n\n# we then map each of them to the following categorical levels\nthal_mappings = {3.0 : 'thal3', 6.0 : 'thal6', 7.0 : 'thal7'}\ndata['thal'].replace(thal_mappings,inplace=True)\n\n# output the result\nprint(f\"After processing the variable \\\"thal\\\" has the following value counts:\\n{data['thal'].value_counts()}\\n\")",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Before processing the variable \"cpt\" has the following value counts:\n4.0    129\n3.0     79\n2.0     42\n1.0     20\nName: cpt, dtype: int64\n\nAfter processing the variable \"cpt\" has the following value counts:\ncpt4    129\ncpt3     79\ncpt2     42\ncpt1     20\nName: cpt, dtype: int64\n\nBefore processing the variable \"rer\" has the following value counts:\n2.0    137\n0.0    131\n1.0      2\nName: rer, dtype: int64\n\nAfter processing the variable \"rer\" has the following value counts:\nrer2    137\nrer0    131\nrer1      2\nName: rer, dtype: int64\n\nBefore processing the variable \"thal\" has the following value counts:\n3.0    152\n7.0    104\n6.0     14\nName: thal, dtype: int64\n\nAfter processing the variable \"thal\" has the following value counts:\nthal3    152\nthal7    104\nthal6     14\nName: thal, dtype: int64\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that we've undone the integer encoding, we're ready to apply one-hot encoding to these nominal variables."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# one-hot encode\ndata = pd.get_dummies(data)\n# display transformed data\ndata.head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>rb</th>\n      <th>sc</th>\n      <th>fbs</th>\n      <th>mha</th>\n      <th>eia</th>\n      <th>old</th>\n      <th>sope</th>\n      <th>nomv</th>\n      <th>cpt_cpt1</th>\n      <th>cpt_cpt2</th>\n      <th>cpt_cpt3</th>\n      <th>cpt_cpt4</th>\n      <th>rer_rer0</th>\n      <th>rer_rer1</th>\n      <th>rer_rer2</th>\n      <th>thal_thal3</th>\n      <th>thal_thal6</th>\n      <th>thal_thal7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70.0</td>\n      <td>1.0</td>\n      <td>130.0</td>\n      <td>322.0</td>\n      <td>0.0</td>\n      <td>109.0</td>\n      <td>0.0</td>\n      <td>2.4</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>115.0</td>\n      <td>564.0</td>\n      <td>0.0</td>\n      <td>160.0</td>\n      <td>0.0</td>\n      <td>1.6</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>124.0</td>\n      <td>261.0</td>\n      <td>0.0</td>\n      <td>141.0</td>\n      <td>0.0</td>\n      <td>0.3</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>64.0</td>\n      <td>1.0</td>\n      <td>128.0</td>\n      <td>263.0</td>\n      <td>0.0</td>\n      <td>105.0</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>74.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>269.0</td>\n      <td>0.0</td>\n      <td>121.0</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    age  sex     rb     sc  fbs    mha  eia  old  sope  nomv  cpt_cpt1  \\\n0  70.0  1.0  130.0  322.0  0.0  109.0  0.0  2.4   2.0   3.0         0   \n1  67.0  0.0  115.0  564.0  0.0  160.0  0.0  1.6   2.0   0.0         0   \n2  57.0  1.0  124.0  261.0  0.0  141.0  0.0  0.3   1.0   0.0         0   \n3  64.0  1.0  128.0  263.0  0.0  105.0  1.0  0.2   2.0   1.0         0   \n4  74.0  0.0  120.0  269.0  0.0  121.0  1.0  0.2   1.0   1.0         0   \n\n   cpt_cpt2  cpt_cpt3  cpt_cpt4  rer_rer0  rer_rer1  rer_rer2  thal_thal3  \\\n0         0         0         1         0         0         1           1   \n1         0         1         0         0         0         1           0   \n2         1         0         0         1         0         0           0   \n3         0         0         1         1         0         0           0   \n4         1         0         0         0         0         1           1   \n\n   thal_thal6  thal_thal7  \n0           0           0  \n1           0           1  \n2           0           1  \n3           0           1  \n4           0           0  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that our descriptive features are encoded correctly we can scale our data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import preprocessing\n\n# save a copy of the original data\ndata_copy = data.copy()\n# perform scaling\nscaler = preprocessing.MinMaxScaler()\nscaler.fit(data)\ndata = scaler.fit_transform(data)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Our data has now been processed and scaled and we're ready to move to the next section."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Exploration & Visualisation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Predictive Modelling"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Feature Selection\nTo achieve better performance and avoid pitfalls such as overfitting, we will peform feature selection on our dataset to determine whether an optimal subset of our descriptive features might suffice. Our chosen method of feature selection is random forest importance."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "'''\nCLEAN THIS UP JUST MAKING SURE IT RUNS PROPERLY ETC\n'''\n\nimport altair as alt\n#%%capture\n#!pip install --upgrade altair\n#!pip install vega vega_datasets\nalt.renderers.enable('notebook')\n\nfrom sklearn import feature_selection as fs\nfrom sklearn.ensemble import RandomForestClassifier\n\n# first determine the number of features we wish to examine, \n# intially we wish to look at all of them for visualisation\nnum_features = 13\nmodel_rfi = RandomForestClassifier(n_estimators=100)\nmodel_rfi.fit(data, encoded_target)\nfs_indices_rfi = np.argsort(model_rfi.feature_importances_)[::-1][0:num_features]\n\n# get the best features\nbest_features_rfi = data_copy.columns[fs_indices_rfi].values\nbest_features_rfi\n\n# get their importances\nfeature_importances_rfi = model_rfi.feature_importances_[fs_indices_rfi]\nfeature_importances_rfi\n\n# taken from SK2\ndef plot_imp(best_features, scores, method_name, color):\n    \n    df = pd.DataFrame({'features': best_features, \n                       'importances': scores})\n    \n    chart = alt.Chart(df, \n                      width=500, \n                      title=method_name + ' Feature Importances'\n                     ).mark_bar(opacity=0.75, \n                                color=color).encode(\n        alt.X('features', title='Feature', sort=None, axis=alt.AxisConfig(labelAngle=45)),\n        alt.Y('importances', title='Importance')\n    )\n    \n    return chart\n\n# plot\nplot_imp(best_features_rfi, feature_importances_rfi, 'Random Forest', 'blue')",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": "const spec = {\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-bbcc13e72a058b89374f3090e8c06f22\"}, \"mark\": {\"type\": \"bar\", \"color\": \"blue\", \"opacity\": 0.75}, \"encoding\": {\"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 45}, \"field\": \"features\", \"sort\": null, \"title\": \"Feature\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"importances\", \"title\": \"Importance\"}}, \"title\": \"Random Forest Feature Importances\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-bbcc13e72a058b89374f3090e8c06f22\": [{\"features\": \"nomv\", \"importances\": 0.10641077961525937}, {\"features\": \"mha\", \"importances\": 0.1040587896540334}, {\"features\": \"thal_thal3\", \"importances\": 0.09945932985702598}, {\"features\": \"old\", \"importances\": 0.09654981261655098}, {\"features\": \"cpt_cpt4\", \"importances\": 0.08623858608075265}, {\"features\": \"sc\", \"importances\": 0.08076959289966648}, {\"features\": \"age\", \"importances\": 0.07759431672840039}, {\"features\": \"thal_thal7\", \"importances\": 0.0690620938329155}, {\"features\": \"rb\", \"importances\": 0.06839739935372652}, {\"features\": \"sope\", \"importances\": 0.05312788026593127}, {\"features\": \"eia\", \"importances\": 0.03757654573130252}, {\"features\": \"sex\", \"importances\": 0.029543839513002074}, {\"features\": \"cpt_cpt3\", \"importances\": 0.0261450642378892}]}};\nconst opt = {};\nconst type = \"vega-lite\";\nconst id = \"ca1e9d4b-ab58-4684-96d8-70245923cf7e\";\n\nconst output_area = this;\n\nrequire([\"nbextensions/jupyter-vega/index\"], function(vega) {\n  const target = document.createElement(\"div\");\n  target.id = id;\n  target.className = \"vega-embed\";\n\n  const style = document.createElement(\"style\");\n  style.textContent = [\n    \".vega-embed .error p {\",\n    \"  color: firebrick;\",\n    \"  font-size: 14px;\",\n    \"}\",\n  ].join(\"\\\\n\");\n\n  // element is a jQuery wrapped DOM element inside the output area\n  // see http://ipython.readthedocs.io/en/stable/api/generated/\\\n  // IPython.display.html#IPython.display.Javascript.__init__\n  element[0].appendChild(target);\n  element[0].appendChild(style);\n\n  vega.render(\"#\" + id, spec, type, opt, output_area);\n}, function (err) {\n  if (err.requireType !== \"scripterror\") {\n    throw(err);\n  }\n});\n",
            "text/plain": "<vega.vegalite.VegaLite at 0x7fd76b4d64e0>"
          },
          "metadata": {
            "jupyter-vega": "#ca1e9d4b-ab58-4684-96d8-70245923cf7e"
          }
        },
        {
          "data": {
            "image/png": "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"
          },
          "metadata": {
            "jupyter-vega": "#ca1e9d4b-ab58-4684-96d8-70245923cf7e"
          },
          "output_type": "display_data"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train-test Splitting\nTo fit and evaluate our models we require that our data be split into training and testing sets. Note that to preserve the proportion on positive and negative instances of our target across the training and test sets we set the stratify option to the target."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nrandom_seed = 999\n\nd_train, d_test,t_train, t_test = train_test_split(data, encoded_target, \n                                                    test_size = 0.3, \n                                                    stratify = encoded_target,   \n                                                    random_state=random_seed)\n\nprint(d_train.shape)\nprint(d_test.shape)\ntarget.value_counts()",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(189, 20)\n(81, 20)\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "1    150\n2    120\nName: target, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Cross-Validation\nTo assess the performance of our models we will be using repeated stratified 10-fold cross-validation with 5 repetitions. Stratified cross-validation was selected to ensure the proportion of positive and negatives labels in the target is preserved in each repetition."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n\ncv_method = RepeatedStratifiedKFold(n_splits=10, \n                                    n_repeats=5, \n                                    random_state=random_seed)\n\n# to do...",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Hyperparameter Tuning\nIn order to ensure that our machine learning models are optimal, it is necessary to perform hyperparameter tuning. Our chosen tuning method is grid search."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}