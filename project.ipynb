{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Machine Learning Project"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Introduction"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The aim of this project is to predict the presence of heart disease using a dataset obtained from the UCL Machine Learning repository. The dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/statlog+%28heart%29). \n\n*INSERT OUTLINE OF METHODOLOGY AFTER PROJECT*"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Description"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Our data consists of 270 instances with 13 descriptive features, and a target feature having two classes which indicate the presence or absence of heart disease. Hence, this is a binary classification problem. As is, our dataset contains no missing values.\n\nThe following explanation of the descriptive features is extracted from the dataset description on the [UCL website](https://archive.ics.uci.edu/ml/datasets/statlog+%28heart%29):\n* age - **numerical**\n* sex - **binary**\n* chest pain type - **nominal**\n* resting blood pressure - **numerical**\n* serum cholestoral in mg/dl - **numerical**      \n* fasting blood sugar > 120 mg/dl - **binary**\n* resting electrocardiographic results - **nominal**\n* maximum heart rate achieved - **numerical**\n* exercise induced angina - **binary**\n* oldpeak = ST depression induced by exercise relative to rest - **numerical**\n* the slope of the peak exercise ST segment - **ordinal**\n* number of major vessels (0-3) colored by flourosopy - **numerical**    \n* thal - **nominal**\n\nEach of the nominal features has been integer encoded, which is a miselading representation of the data and will be addressed in the processing stage. \n\nTime to import our dataset as well as any modules we will be using, and do some preliminary configuration."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\n\n# Ignore python warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# display all columns\npd.set_option('display.max_columns', None) \n\n# read in and configure data with column names\n# col_names = ['age', 'sex', 'chest_pain_type', 'resting_bp', 'serum_cholestoral', 'fasting_blood_sugar', 'resting_ecg_results', 'max_hr_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_of_peak_exercise', 'no_of_major_vessels', 'thal', 'target']\n# these names are abbreviated below for space\ncol_names = ['age', 'sex', 'cpt', 'rb', 'sc', 'fbs', 'rer', 'mha', 'eia', 'old', 'sope', 'nomv', 'thal', 'target'] \ndata = pd.read_csv('heart.csv',names=col_names,header=None)\n\n# separate target feature\ntarget = data['target']\ndata.drop(columns=['target'],inplace=True)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that we have our dataset imported and our target feature separated we can have a brief look at our dataset using python."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"----------\")\nprint(f\"Shape of the dataset is {data.shape} \\n\")\nprint(\"----------\")\nprint(f\"Each of the descriptive features have the following types:\\n{data.dtypes}\\n\")\nprint(\"----------\")\nprint(f\"Each of the descriptive features have the following number of unique values:\\n{data.nunique()}\\n\")\nprint(\"----------\")\nprint(f\"The dataset contains no missing values:\\n{data.isna().sum()}\\n\")\ndata.head(20)",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "----------\nShape of the dataset is (270, 13) \n\n----------\nEach of the descriptive features have the following types:\nage     float64\nsex     float64\ncpt     float64\nrb      float64\nsc      float64\nfbs     float64\nrer     float64\nmha     float64\neia     float64\nold     float64\nsope    float64\nnomv    float64\nthal    float64\ndtype: object\n\n----------\nEach of the descriptive features have the following number of unique values:\nage      41\nsex       2\ncpt       4\nrb       47\nsc      144\nfbs       2\nrer       3\nmha      90\neia       2\nold      39\nsope      3\nnomv      4\nthal      3\ndtype: int64\n\n----------\nThe dataset contains no missing values:\nage     0\nsex     0\ncpt     0\nrb      0\nsc      0\nfbs     0\nrer     0\nmha     0\neia     0\nold     0\nsope    0\nnomv    0\nthal    0\ndtype: int64\n\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cpt</th>\n      <th>rb</th>\n      <th>sc</th>\n      <th>fbs</th>\n      <th>rer</th>\n      <th>mha</th>\n      <th>eia</th>\n      <th>old</th>\n      <th>sope</th>\n      <th>nomv</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>130.0</td>\n      <td>322.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>109.0</td>\n      <td>0.0</td>\n      <td>2.4</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>115.0</td>\n      <td>564.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>160.0</td>\n      <td>0.0</td>\n      <td>1.6</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>124.0</td>\n      <td>261.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>141.0</td>\n      <td>0.0</td>\n      <td>0.3</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>64.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>128.0</td>\n      <td>263.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>105.0</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>74.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>120.0</td>\n      <td>269.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>121.0</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>65.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>120.0</td>\n      <td>177.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>140.0</td>\n      <td>0.0</td>\n      <td>0.4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>56.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>130.0</td>\n      <td>256.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>142.0</td>\n      <td>1.0</td>\n      <td>0.6</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>59.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>110.0</td>\n      <td>239.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>142.0</td>\n      <td>1.0</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>140.0</td>\n      <td>293.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>170.0</td>\n      <td>0.0</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>63.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>150.0</td>\n      <td>407.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>154.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>59.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>135.0</td>\n      <td>234.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>161.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>53.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>142.0</td>\n      <td>226.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>111.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>44.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>140.0</td>\n      <td>235.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>180.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>61.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>134.0</td>\n      <td>234.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>145.0</td>\n      <td>0.0</td>\n      <td>2.6</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>128.0</td>\n      <td>303.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>159.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>71.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>112.0</td>\n      <td>149.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>125.0</td>\n      <td>0.0</td>\n      <td>1.6</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>46.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>140.0</td>\n      <td>311.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>1.0</td>\n      <td>1.8</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>53.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>140.0</td>\n      <td>203.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>155.0</td>\n      <td>1.0</td>\n      <td>3.1</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>64.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>110.0</td>\n      <td>211.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>144.0</td>\n      <td>1.0</td>\n      <td>1.8</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>40.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>140.0</td>\n      <td>199.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>178.0</td>\n      <td>1.0</td>\n      <td>1.4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "     age  sex  cpt     rb     sc  fbs  rer    mha  eia  old  sope  nomv  thal\n0   70.0  1.0  4.0  130.0  322.0  0.0  2.0  109.0  0.0  2.4   2.0   3.0   3.0\n1   67.0  0.0  3.0  115.0  564.0  0.0  2.0  160.0  0.0  1.6   2.0   0.0   7.0\n2   57.0  1.0  2.0  124.0  261.0  0.0  0.0  141.0  0.0  0.3   1.0   0.0   7.0\n3   64.0  1.0  4.0  128.0  263.0  0.0  0.0  105.0  1.0  0.2   2.0   1.0   7.0\n4   74.0  0.0  2.0  120.0  269.0  0.0  2.0  121.0  1.0  0.2   1.0   1.0   3.0\n5   65.0  1.0  4.0  120.0  177.0  0.0  0.0  140.0  0.0  0.4   1.0   0.0   7.0\n6   56.0  1.0  3.0  130.0  256.0  1.0  2.0  142.0  1.0  0.6   2.0   1.0   6.0\n7   59.0  1.0  4.0  110.0  239.0  0.0  2.0  142.0  1.0  1.2   2.0   1.0   7.0\n8   60.0  1.0  4.0  140.0  293.0  0.0  2.0  170.0  0.0  1.2   2.0   2.0   7.0\n9   63.0  0.0  4.0  150.0  407.0  0.0  2.0  154.0  0.0  4.0   2.0   3.0   7.0\n10  59.0  1.0  4.0  135.0  234.0  0.0  0.0  161.0  0.0  0.5   2.0   0.0   7.0\n11  53.0  1.0  4.0  142.0  226.0  0.0  2.0  111.0  1.0  0.0   1.0   0.0   7.0\n12  44.0  1.0  3.0  140.0  235.0  0.0  2.0  180.0  0.0  0.0   1.0   0.0   3.0\n13  61.0  1.0  1.0  134.0  234.0  0.0  0.0  145.0  0.0  2.6   2.0   2.0   3.0\n14  57.0  0.0  4.0  128.0  303.0  0.0  2.0  159.0  0.0  0.0   1.0   1.0   3.0\n15  71.0  0.0  4.0  112.0  149.0  0.0  0.0  125.0  0.0  1.6   2.0   0.0   3.0\n16  46.0  1.0  4.0  140.0  311.0  0.0  0.0  120.0  1.0  1.8   2.0   2.0   7.0\n17  53.0  1.0  4.0  140.0  203.0  1.0  2.0  155.0  1.0  3.1   3.0   0.0   7.0\n18  64.0  1.0  1.0  110.0  211.0  0.0  2.0  144.0  1.0  1.8   2.0   0.0   3.0\n19  40.0  1.0  1.0  140.0  199.0  0.0  0.0  178.0  1.0  1.4   1.0   0.0   7.0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Preparation\n<a id='dataprep'></a>\nWhile our dataset comes to us fairly clean, there is still much data preparation to do before we can get to the business of predictive modelling.\n\nFirst of all, we must integer encode the target feature. It is holds the values (1) for the absence of heart disease, and (2) for the presence of heart disease. Since the presence is our postive feature, we wish to map this to (1) and the absence to (0)."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# firstly we integer encode target feature \nprint(\"Target before encoding: \",np.unique(target,return_counts=True))\nencoded_target = np.where(target==1,0,1)\nprint(\"Target after encoding: \",np.unique(encoded_target,return_counts=True))",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Target before encoding:  (array([1, 2]), array([150, 120]))\nTarget after encoding:  (array([0, 1]), array([150, 120]))\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We now turn to our nominal features which have been integer encoded. As integer encoding assumes an ordering, we consider it bad practice to integer encode nominal features, so we will undo this encoding and repace it with a one-hot encoding scheme."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# the variable \"chest_pain_type\" or \"cpt\" has the following values:\ndata['cpt'].value_counts()\n# we map each of them to the following categorical levels\ncpt_mappings = {1.0 : 'l1', 2.0 : 'l2', 3.0 : 'l3', 4.0 : 'l4'}\ndata['cpt'] = data['cpt'].replace(cpt_mappings)\n\n# NO MISSING VALUES - but are there outliers?\n\n# integer encode all binary features: sex, fsb, eia\n\n# NOMINAL AND ORDINAL FEATURES ALREADY INTEGER ENCODED - one-hot encode nominal?\n\n# scale features",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "0      l4\n1      l3\n2      l2\n3      l4\n4      l2\n5      l4\n6      l3\n7      l4\n8      l4\n9      l4\n10     l4\n11     l4\n12     l3\n13     l1\n14     l4\n15     l4\n16     l4\n17     l4\n18     l1\n19     l1\n20     l4\n21     l2\n22     l4\n23     l4\n24     l2\n25     l3\n26     l4\n27     l3\n28     l3\n29     l3\n       ..\n240    l3\n241    l3\n242    l4\n243    l4\n244    l3\n245    l4\n246    l4\n247    l3\n248    l3\n249    l4\n250    l4\n251    l2\n252    l4\n253    l3\n254    l3\n255    l2\n256    l3\n257    l4\n258    l3\n259    l4\n260    l3\n261    l4\n262    l2\n263    l2\n264    l2\n265    l3\n266    l2\n267    l2\n268    l4\n269    l4\nName: cpt, Length: 270, dtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Exploration & Visualisation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}