{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Machine Learning Project"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Introduction"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The aim of this project is to predict the presence of heart disease using a dataset obtained from the UCL Machine Learning repository. The dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/statlog+%28heart%29). \n\n*INSERT OUTLINE OF METHODOLOGY AFTER PROJECT* classifiers are KNN, DT, NB, RF"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Description"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Our data consists of 270 instances with 13 descriptive features, and a target feature having two classes which indicate the presence or absence of heart disease. Hence, this is a binary classification problem. As is, our dataset contains no missing values.\n\nThe following explanation of the descriptive features is extracted from the dataset description on the [UCL website](https://archive.ics.uci.edu/ml/datasets/statlog+%28heart%29):\n* age - **numerical**\n* sex - **binary**\n* chest pain type - **nominal**\n* resting blood pressure - **numerical**\n* serum cholestoral in mg/dl - **numerical**      \n* fasting blood sugar > 120 mg/dl - **binary**\n* resting electrocardiographic results - **nominal**\n* maximum heart rate achieved - **numerical**\n* exercise induced angina - **binary**\n* oldpeak = ST depression induced by exercise relative to rest - **numerical**\n* the slope of the peak exercise ST segment - **ordinal**\n* number of major vessels (0-3) colored by flourosopy - **numerical**    \n* thal - **nominal**\n\nEach of the nominal features has been integer encoded, which is a miselading representation of the data and will be addressed in the processing stage. \n\nTime to import our dataset as well as any modules we will be using, and do some preliminary configuration."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\n# for plotting\n#!pip install --upgrade altair\n#!pip install vega vega_datasets\n\n# Ignore python warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# set random state for reproducibility\nrandom_seed = 999\n\n# display all columns\npd.set_option('display.max_columns', None) \n\n# read in and configure data with column names\n# col_names = ['age', 'sex', 'chest_pain_type', 'resting_bp', 'serum_cholestoral', 'fasting_blood_sugar', 'resting_ecg_results', 'max_hr_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_of_peak_exercise', 'no_of_major_vessels', 'thal', 'target']\n# these names are abbreviated below for space\ncol_names = ['age', 'sex', 'cpt', 'rb', 'sc', 'fbs', 'rer', 'mha', 'eia', 'old', 'sope', 'nomv', 'thal', 'target'] \ndata = pd.read_csv('heart.csv',names=col_names,header=None)\n\n# separate target feature\ntarget = data['target']\ndata.drop(columns=['target'],inplace=True)",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that we have our dataset imported and our target feature separated we can have a brief look at our dataset using python."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"----------\")\nprint(f\"Shape of the dataset is {data.shape} \\n\")\nprint(\"----------\")\nprint(f\"Each of the descriptive features have the following types:\\n{data.dtypes}\\n\")\nprint(\"----------\")\nprint(f\"Each of the descriptive features have the following number of unique values:\\n{data.nunique()}\\n\")\nprint(\"----------\")\nprint(f\"The dataset contains no missing values:\\n{data.isna().sum()}\\n\")",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "----------\nShape of the dataset is (270, 13) \n\n----------\nEach of the descriptive features have the following types:\nage     float64\nsex     float64\ncpt     float64\nrb      float64\nsc      float64\nfbs     float64\nrer     float64\nmha     float64\neia     float64\nold     float64\nsope    float64\nnomv    float64\nthal    float64\ndtype: object\n\n----------\nEach of the descriptive features have the following number of unique values:\nage      41\nsex       2\ncpt       4\nrb       47\nsc      144\nfbs       2\nrer       3\nmha      90\neia       2\nold      39\nsope      3\nnomv      4\nthal      3\ndtype: int64\n\n----------\nThe dataset contains no missing values:\nage     0\nsex     0\ncpt     0\nrb      0\nsc      0\nfbs     0\nrer     0\nmha     0\neia     0\nold     0\nsope    0\nnomv    0\nthal    0\ndtype: int64\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Preparation\n<a id='dataprep'></a>\nWhile our dataset comes to us fairly clean, there is still much data preparation to do before we can get to the business of predictive modelling.\n\nFirst of all, we must integer encode the target feature. It currently holds the values (1) for the absence of heart disease, and (2) for the presence of heart disease. Since the presence is our postive feature, we wish to map this to (1) and the absence to (0)."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# firstly we integer encode target feature \nprint(\"Target before encoding: \",np.unique(target,return_counts=True))\nencoded_target = np.where(target==1,0,1)\nprint(\"Target after encoding: \",np.unique(encoded_target,return_counts=True))",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Target before encoding:  (array([1, 2]), array([150, 120]))\nTarget after encoding:  (array([0, 1]), array([150, 120]))\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We now turn to our nominal features (chest pain type, resting electrocardiographic results, and thal) which have been integer encoded. As integer encoding assumes an ordering, we consider it bad practice to integer encode nominal features, so we will undo this encoding to repace it with a one-hot encoding scheme."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# output the value counts for variable 'cpt'\nprint(f\"Before processing the variable \\\"cpt\\\" has the following value counts:\\n{data['cpt'].value_counts()}\\n\")\n\n# we then map each of them to the following categorical levels\ncpt_mappings = {1.0 : 'cpt1', 2.0 : 'cpt2', 3.0 : 'cpt3', 4.0 : 'cpt4'}\ndata['cpt'].replace(cpt_mappings,inplace=True)\n\n# output the result\nprint(f\"After processing the variable \\\"cpt\\\" has the following value counts:\\n{data['cpt'].value_counts()}\\n\")\n\n# output the value counts for variable 'rer'\nprint(f\"Before processing the variable \\\"rer\\\" has the following value counts:\\n{data['rer'].value_counts()}\\n\")\n\n# we then map each of them to the following categorical levels\nrer_mappings = {0.0 : 'rer0', 1.0 : 'rer1', 2.0 : 'rer2'}\ndata['rer'].replace(rer_mappings,inplace=True)\n\n# output the result\nprint(f\"After processing the variable \\\"rer\\\" has the following value counts:\\n{data['rer'].value_counts()}\\n\")\n\n# output the value counts for variable 'thal'\nprint(f\"Before processing the variable \\\"thal\\\" has the following value counts:\\n{data['thal'].value_counts()}\\n\")\n\n# we then map each of them to the following categorical levels\nthal_mappings = {3.0 : 'thal3', 6.0 : 'thal6', 7.0 : 'thal7'}\ndata['thal'].replace(thal_mappings,inplace=True)\n\n# output the result\nprint(f\"After processing the variable \\\"thal\\\" has the following value counts:\\n{data['thal'].value_counts()}\\n\")",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Before processing the variable \"cpt\" has the following value counts:\n4.0    129\n3.0     79\n2.0     42\n1.0     20\nName: cpt, dtype: int64\n\nAfter processing the variable \"cpt\" has the following value counts:\ncpt4    129\ncpt3     79\ncpt2     42\ncpt1     20\nName: cpt, dtype: int64\n\nBefore processing the variable \"rer\" has the following value counts:\n2.0    137\n0.0    131\n1.0      2\nName: rer, dtype: int64\n\nAfter processing the variable \"rer\" has the following value counts:\nrer2    137\nrer0    131\nrer1      2\nName: rer, dtype: int64\n\nBefore processing the variable \"thal\" has the following value counts:\n3.0    152\n7.0    104\n6.0     14\nName: thal, dtype: int64\n\nAfter processing the variable \"thal\" has the following value counts:\nthal3    152\nthal7    104\nthal6     14\nName: thal, dtype: int64\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that we've undone the integer encoding, we're ready to apply one-hot encoding to these nominal variables."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# one-hot encode\ndata = pd.get_dummies(data)\n# display transformed data\ndata.head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>rb</th>\n      <th>sc</th>\n      <th>fbs</th>\n      <th>mha</th>\n      <th>eia</th>\n      <th>old</th>\n      <th>sope</th>\n      <th>nomv</th>\n      <th>cpt_cpt1</th>\n      <th>cpt_cpt2</th>\n      <th>cpt_cpt3</th>\n      <th>cpt_cpt4</th>\n      <th>rer_rer0</th>\n      <th>rer_rer1</th>\n      <th>rer_rer2</th>\n      <th>thal_thal3</th>\n      <th>thal_thal6</th>\n      <th>thal_thal7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70.0</td>\n      <td>1.0</td>\n      <td>130.0</td>\n      <td>322.0</td>\n      <td>0.0</td>\n      <td>109.0</td>\n      <td>0.0</td>\n      <td>2.4</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>115.0</td>\n      <td>564.0</td>\n      <td>0.0</td>\n      <td>160.0</td>\n      <td>0.0</td>\n      <td>1.6</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>124.0</td>\n      <td>261.0</td>\n      <td>0.0</td>\n      <td>141.0</td>\n      <td>0.0</td>\n      <td>0.3</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>64.0</td>\n      <td>1.0</td>\n      <td>128.0</td>\n      <td>263.0</td>\n      <td>0.0</td>\n      <td>105.0</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>74.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>269.0</td>\n      <td>0.0</td>\n      <td>121.0</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    age  sex     rb     sc  fbs    mha  eia  old  sope  nomv  cpt_cpt1  \\\n0  70.0  1.0  130.0  322.0  0.0  109.0  0.0  2.4   2.0   3.0         0   \n1  67.0  0.0  115.0  564.0  0.0  160.0  0.0  1.6   2.0   0.0         0   \n2  57.0  1.0  124.0  261.0  0.0  141.0  0.0  0.3   1.0   0.0         0   \n3  64.0  1.0  128.0  263.0  0.0  105.0  1.0  0.2   2.0   1.0         0   \n4  74.0  0.0  120.0  269.0  0.0  121.0  1.0  0.2   1.0   1.0         0   \n\n   cpt_cpt2  cpt_cpt3  cpt_cpt4  rer_rer0  rer_rer1  rer_rer2  thal_thal3  \\\n0         0         0         1         0         0         1           1   \n1         0         1         0         0         0         1           0   \n2         1         0         0         1         0         0           0   \n3         0         0         1         1         0         0           0   \n4         1         0         0         0         0         1           1   \n\n   thal_thal6  thal_thal7  \n0           0           0  \n1           0           1  \n2           0           1  \n3           0           1  \n4           0           0  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that our descriptive features are encoded correctly we can scale our data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import preprocessing\n\n# save a copy of the original data\ndata_copy = data.copy()\n# perform scaling\nscaler = preprocessing.MinMaxScaler()\nscaler.fit(data)\ndata = scaler.fit_transform(data)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Our data has now been processed and scaled and we're ready to move to the next section."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data Exploration & Visualisation"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Predictive Modelling"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Cross-Validation\nTo assess the performance of our models we will be using repeated stratified 10-fold cross-validation with 5 repetitions. Stratified cross-validation was selected to ensure the proportion of positive and negatives labels in the target is preserved in each repetition. - CHECK WHETHER THIS IS THE BEST WAY TO DO IT"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n\ncv_method = RepeatedStratifiedKFold(n_splits=10, \n                                    n_repeats=5, \n                                    random_state=random_seed)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Feature Selection\nWe will peform feature selection using random forest importance (RFI) on our dataset to determine whether an optimal subset of our descriptive features might give better performance. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "'''\nCLEAN THIS UP JUST MAKING SURE IT RUNS PROPERLY ETC\n'''\n# for plotting\nimport altair as alt\nalt.renderers.enable('notebook')\n\nfrom sklearn import feature_selection as fs\nfrom sklearn.ensemble import RandomForestClassifier\n\n# intially we wish to look at all of our features\n\nnum_features = 20\n\nmodel_rfi = RandomForestClassifier(n_estimators=100)\nmodel_rfi.fit(data, encoded_target)\nfs_indices_rfi = np.argsort(model_rfi.feature_importances_)[::-1][0:num_features]\n\n# get all features in sorted order of importance\nbest_features_rfi = data_copy.columns[fs_indices_rfi].values\n\n# get their importances\nfeature_importances_rfi = model_rfi.feature_importances_[fs_indices_rfi]\n\n# taken from SK2\ndef plot_imp(best_features, scores, method_name, x_label, y_label):\n    \n    df = pd.DataFrame({x_label : best_features, \n                       y_label : scores})\n    \n    chart = alt.Chart(df, \n                      width=500, \n                      title=method_name,\n                     ).mark_bar(opacity=0.75, \n                                color='blue').encode(\n        alt.X(x_label, title=x_label, sort=None, axis=alt.AxisConfig(labelAngle=45)),\n        alt.Y(y_label, title=y_label)\n    )\n    \n    return chart\n\n# plot\nplot_imp(best_features_rfi, feature_importances_rfi, 'Random Forest Feature Importances','features','importances')",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": "const spec = {\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-def976d62299bcef3ef77de0f54e2626\"}, \"mark\": {\"type\": \"bar\", \"color\": \"blue\", \"opacity\": 0.75}, \"encoding\": {\"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 45}, \"field\": \"features\", \"sort\": null, \"title\": \"features\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"importances\", \"title\": \"importances\"}}, \"title\": \"Random Forest Feature Importances\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-def976d62299bcef3ef77de0f54e2626\": [{\"features\": \"nomv\", \"importances\": 0.11436889187993879}, {\"features\": \"old\", \"importances\": 0.10090868403137149}, {\"features\": \"mha\", \"importances\": 0.09850467068087855}, {\"features\": \"thal_thal7\", \"importances\": 0.09109189474489146}, {\"features\": \"cpt_cpt4\", \"importances\": 0.090192741879913}, {\"features\": \"thal_thal3\", \"importances\": 0.08089871416840153}, {\"features\": \"age\", \"importances\": 0.08028457633447386}, {\"features\": \"sc\", \"importances\": 0.07926374537944543}, {\"features\": \"rb\", \"importances\": 0.06532396775561605}, {\"features\": \"eia\", \"importances\": 0.04897416839194926}, {\"features\": \"sope\", \"importances\": 0.04162982033721767}, {\"features\": \"sex\", \"importances\": 0.021146194942968936}, {\"features\": \"cpt_cpt3\", \"importances\": 0.019549422790437393}, {\"features\": \"rer_rer2\", \"importances\": 0.017378502300284968}, {\"features\": \"rer_rer0\", \"importances\": 0.013502742965929211}, {\"features\": \"cpt_cpt1\", \"importances\": 0.013458869323574154}, {\"features\": \"fbs\", \"importances\": 0.009627988169342157}, {\"features\": \"cpt_cpt2\", \"importances\": 0.007591910371217517}, {\"features\": \"thal_thal6\", \"importances\": 0.005068457007230866}, {\"features\": \"rer_rer1\", \"importances\": 0.001234036544917877}]}};\nconst opt = {};\nconst type = \"vega-lite\";\nconst id = \"439c9de8-70fb-48b8-871d-816560cf0109\";\n\nconst output_area = this;\n\nrequire([\"nbextensions/jupyter-vega/index\"], function(vega) {\n  const target = document.createElement(\"div\");\n  target.id = id;\n  target.className = \"vega-embed\";\n\n  const style = document.createElement(\"style\");\n  style.textContent = [\n    \".vega-embed .error p {\",\n    \"  color: firebrick;\",\n    \"  font-size: 14px;\",\n    \"}\",\n  ].join(\"\\\\n\");\n\n  // element is a jQuery wrapped DOM element inside the output area\n  // see http://ipython.readthedocs.io/en/stable/api/generated/\\\n  // IPython.display.html#IPython.display.Javascript.__init__\n  element[0].appendChild(target);\n  element[0].appendChild(style);\n\n  vega.render(\"#\" + id, spec, type, opt, output_area);\n}, function (err) {\n  if (err.requireType !== \"scripterror\") {\n    throw(err);\n  }\n});\n",
            "text/plain": "<vega.vegalite.VegaLite at 0x7f42eb9fe128>"
          },
          "metadata": {
            "jupyter-vega": "#439c9de8-70fb-48b8-871d-816560cf0109"
          }
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        },
        {
          "data": {
            "image/png": "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"
          },
          "metadata": {
            "jupyter-vega": "#439c9de8-70fb-48b8-871d-816560cf0109"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the above graph we can see the importances of all of our descriptive features sorted in descreasing order of importance. Let us now measure the accuracy of a number of feature subsets to determine if one is optimal using a KNN classifier using the eulidean distance metric with n=5 neighbours."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\n\nfs_knn = KNeighborsClassifier(n_neighbors=5)\n\nnum_features = [x for x in range(5,21)]\n\naccuracy_scores = list()\n\nfor n in num_features:\n    \n    # subset data into the first n most important features\n    subset = data[:, fs_indices_rfi[:n]]\n    \n    # assess accuracy and record\n    cv_results_fs = cross_val_score(estimator=fs_knn,\n                             X=subset,\n                             y=encoded_target, \n                             cv=cv_method, \n                             scoring='accuracy')\n\n    accuracy_scores.append(cv_results_fs.mean().round(3))\n    \n# display scores in sorted order\nacc_df = pd.DataFrame({'num_features': num_features, \n                       'accuracy': accuracy_scores}).sort_values(by=['accuracy'])\nacc_df",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_features</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>17</td>\n      <td>0.787</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>18</td>\n      <td>0.790</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>20</td>\n      <td>0.791</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>13</td>\n      <td>0.792</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>19</td>\n      <td>0.794</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>16</td>\n      <td>0.798</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>12</td>\n      <td>0.804</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>11</td>\n      <td>0.807</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>15</td>\n      <td>0.807</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10</td>\n      <td>0.810</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>0.813</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>0.815</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>14</td>\n      <td>0.815</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>0.817</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>0.823</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>0.823</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    num_features  accuracy\n12            17     0.787\n13            18     0.790\n15            20     0.791\n8             13     0.792\n14            19     0.794\n11            16     0.798\n7             12     0.804\n6             11     0.807\n10            15     0.807\n5             10     0.810\n3              8     0.813\n2              7     0.815\n9             14     0.815\n1              6     0.817\n0              5     0.823\n4              9     0.823"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Above we see that using only the 6 (THIS VALUE WILL CHANGE) most important features yields us the greatest accuracy. However, due to constraints placed upon our dataset (i.e. a minimum of 7 descriptive features) we will select the first 9, which our tests indicate is practically the same as choosing 6 in terms of accuracy. We therefore subset our data accordingly before proceeding."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#data = data[:, fs_indices_rfi[:9]] # this value can change! be careful!\ndata.shape",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "(270, 20)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train-test Splitting\nTo fit and evaluate our models we require that our data be split into training and testing sets. Note that to preserve the proportion of positive and negative instances of our target across the training and test sets we set the stratify option to the target."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nd_train, d_test,t_train, t_test = train_test_split(data, encoded_target, \n                                                    test_size = 0.3, \n                                                    stratify = encoded_target,   \n                                                    random_state=random_seed)\n\nprint(d_train.shape)\nprint(d_test.shape)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(189, 20)\n(81, 20)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Hyperparameter Tuning\nIn order to ensure that our machine learning models are optimal, it is necessary to perform hyperparameter tuning. Our chosen tuning method is grid search."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}